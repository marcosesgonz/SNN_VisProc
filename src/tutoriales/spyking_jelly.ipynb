{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marcos Esquivel González"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spike = tensor([0., 0., 1., 1., 0., 0., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "v = torch.rand([8])\n",
    "v_th = 0.5\n",
    "spike = (v >= v_th).to(v)#Con el método 'to(v)', hago que el tensor tenga el mismo dtype y se almacene en el mismo dispositivo que 'v'.\n",
    "print('spike =', spike)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Format\n",
    "-------------------------------------------\n",
    "In ``spikingjelly.activation_based``, There are two formats of data:\n",
    "\n",
    "* Data in a single time-step with ``shape = [N, *]``, where ``N`` is the batch dimension, ``*`` represents any extra dimensions.\n",
    "* Data in many time-steps with ``shape = [T, N, *]``, where ``T`` is the time-step dimension, ``N`` is the batch dimension and `*` represents any additional dimensions.\n",
    "\n",
    "Step Mode\n",
    "-------------------------------------------\n",
    "Modules in ``spikingjelly.activation_based`` have two propagation modes, which are the single-step mode 's' and the multi-step mode 'm'. In single-step mode, the data use the ``shape = [N, *]`` format. In multi-step mode, the data use the ``shape = [T, N, *]`` format.\n",
    "\n",
    "The user can set ``step_mode`` of a module in its ``__init__`` or change ``step_mode`` anytime after the module is built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from spikingjelly.activation_based import neuron\n",
    "\n",
    "net = neuron.IFNode(step_mode='m')\n",
    "# 'm' is the multi-step mode\n",
    "net.step_mode = 's'\n",
    "# 's' is the single-step mode"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to input the sequence data with ``shape = [T, N, *]`` to a single-step module, we need to implement a for-loop in time-steps manually, \\\n",
    "which splits the sequence data into ``T`` data with ``shape = [N, *]`` and sends the data step-by-step. \\\n",
    "Let's create a new layer of IF neurons, set it to single-step mode, and input sequence data step-by-step:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 3, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "#Se muestra como usar datos en multipaso en una neurona IF monopaso. Vas spliteando cada paso y obteniendo el resultado.\n",
    "import torch\n",
    "from spikingjelly.activation_based import neuron\n",
    "\n",
    "net_s = neuron.IFNode(step_mode='s')\n",
    "T = 4\n",
    "N = 1\n",
    "C = 3\n",
    "H = 8\n",
    "W = 8\n",
    "x_seq = torch.rand([T, N, C, H, W])\n",
    "y_seq = []\n",
    "for t in range(T):\n",
    "    x = x_seq[t]  # x.shape = [N, C, H, W]\n",
    "    y = net_s(x)  # y.shape = [N, C, H, W]\n",
    "    y_seq.append(y.unsqueeze(0)) #Con el unsqueeze se añade una dimensión de tamaño uno en la posición que se indique. Como es en cero pues la primera dimensión.\n",
    "\n",
    "y_seq = torch.cat(y_seq)  #Concatena la lista de tensores\n",
    "# y_seq.shape = [T, N, C, H, W]\n",
    "print(y_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4])\n",
      "tensor([[1, 2, 3, 4]])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Uno del unsqueeze de pytorch\n",
    "\"\"\"\n",
    "x = torch.tensor([1, 2, 3, 4])\n",
    "print(x)\n",
    "print(torch.unsqueeze(x, 0))\n",
    "print(torch.unsqueeze(x, 1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`multi_step_forward <spikingjelly.activation_based.functional.multi_step_forward>` wraps the for-loop in time-steps for single-step modules to handle sequence data with ``shape = [T, N, *]``, which is more convenient to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 3, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from spikingjelly.activation_based import neuron, functional\n",
    "net_s = neuron.IFNode(step_mode='s')\n",
    "T = 4\n",
    "N = 1\n",
    "C = 3\n",
    "H = 8\n",
    "W = 8\n",
    "x_seq = torch.rand([T, N, C, H, W])\n",
    "y_seq = functional.multi_step_forward(x_seq, net_s)\n",
    "print(y_seq.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the best usage is to set the module as a multi-step module directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 3, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from spikingjelly.activation_based import neuron\n",
    "\n",
    "net_m = neuron.IFNode(step_mode='m')\n",
    "T = 4\n",
    "N = 1\n",
    "C = 3\n",
    "H = 8\n",
    "W = 8\n",
    "x_seq = torch.rand([T, N, C, H, W])\n",
    "y_seq = net_m(x_seq)\n",
    "print(y_seq.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To maintain compatibility with codes using older versions of SpikingJelly, the default step mode for all modules in SpikingJelly is single-step."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving and Resetting of States\n",
    "-------------------------------------------\n",
    "Similar to RNN, neurons and other modules in SNN have hidden states, and their outputs `Y[t]` are determined not only by the input  `X[t]` at the current time-step `t`, \\\n",
    "but also by the state `H[t-1]` at last time-step `t-1`, which is `Y[t] = f(X[t], H[t-1])`.\n",
    "\n",
    "In PyTorch, RNN outputs not only `Y` but also `H`. Refer to `torch.nn.RNN` for more details. Different from PyTorch, the states are stored inside the module in ``spikingjelly.activation_based``. \\\n",
    "For example, let us create a new layer of IF neurons, set them to single-step mode, and check the default voltage before and after giving inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IFNode(\n",
      "  v_threshold=1.0, v_reset=0.0, detach_reset=False, step_mode=s, backend=torch\n",
      "  (surrogate_function): Sigmoid(alpha=4.0, spiking=True)\n",
      ")\n",
      "the initial v=0.0\n",
      "x=tensor([0.2927, 0.2378, 0.8030, 0.4974])\n",
      "y=tensor([0., 0., 0., 0.])\n",
      "v=tensor([0.2927, 0.2378, 0.8030, 0.4974])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from spikingjelly.activation_based import neuron\n",
    "\n",
    "net_s = neuron.IFNode(step_mode='s')\n",
    "x = torch.rand([4])\n",
    "print(net_s)\n",
    "print(f'the initial v={net_s.v}')\n",
    "y = net_s(x)\n",
    "print(f'x={x}')\n",
    "print(f'y={y}')\n",
    "print(f'v={net_s.v}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After initialization, the ``v`` of the IF neurons layer is set to 0 and is automatically broadcast to have the same ``shape`` as the input.\n",
    "\n",
    "If we give a new input sample, we should clear the previous states of the neurons and reset the neurons to the initialization states, which can be done by calling the module's ``self.reset()`` function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check point 0: v=0.0\n",
      "check point 1: v=tensor([0.8037, 0.0571, 0.5728, 0.9937])\n",
      "check point 2: v=0.0\n",
      "check point 3: v=tensor([0.2535, 0.9396, 0.8224, 0.7373, 0.4849, 0.8641, 0.8025, 0.9264])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from spikingjelly.activation_based import neuron\n",
    "\n",
    "net_s = neuron.IFNode(step_mode='s')\n",
    "x = torch.rand([4])\n",
    "print(f'check point 0: v={net_s.v}')\n",
    "y = net_s(x)\n",
    "print(f'check point 1: v={net_s.v}')\n",
    "net_s.reset()\n",
    "print(f'check point 2: v={net_s.v}')\n",
    "x = torch.rand([8])\n",
    "y = net_s(x)\n",
    "print(f'check point 3: v={net_s.v}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, we can also call `spikingjelly.activation_based.functional.reset_net` to reset all modules in a network.\n",
    "\n",
    "If the network uses one or more stateful modules, it must be reset after processing one batch of data during training and inference:\n",
    "\n",
    "..: python\n",
    "\n",
    "    from spikingjelly.activation_based import functional\n",
    "    # ...\n",
    "    for x, label in tqdm(train_data_loader):\n",
    "        # ...\n",
    "        optimizer.zero_grad()\n",
    "        y = net(x)\n",
    "        loss = criterion(y, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        functional.reset_net(net)\n",
    "        # Never forget to reset the network!\n",
    "\n",
    "If we forget to reset, we may get a wrong output during inference or an error during training:\n",
    "\n",
    ".. : shell\n",
    "\n",
    "    RuntimeError: Trying to backward through the graph a second time (or directly access saved variables after they have already been freed). \n",
    "    Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). \n",
    "    Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved variables after calling backward.\n",
    "\n",
    "Propagation Patterns\n",
    "-------------------------------------------\n",
    "If all modules in a network are single-step modules, the computation graph of the entire network is built step-by-step. For example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(T):\n",
    "    x = x_seq[t]\n",
    "    y = net(x)\n",
    "    y_seq_step_by_step.append(y.unsqueeze(0))\n",
    "\n",
    "y_seq_step_by_step = torch.cat(y_seq_step_by_step, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all modules in a network are multi-step modules, the computation graph of the entire network is built layer-by-layer. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from spikingjelly.activation_based import neuron, functional, layer\n",
    "T = 4\n",
    "N = 2\n",
    "C = 8\n",
    "x_seq = torch.rand([T, N, C]) * 64.\n",
    "\n",
    "net = nn.Sequential(\n",
    "    layer.Linear(C, 4), #Capa de entrada con c neuronas va a una con 4 neuronas\n",
    "    neuron.IFNode(),    #La capa usa neuronas IF\n",
    "    layer.Linear(4, 2), #La capa de 4 neuronas va a una de dos neuronas \n",
    "    neuron.IFNode()     #Esta capa de dos neuronas también tendrá neuronas IF\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "El step mode qué es?\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "functional.set_step_mode(net, step_mode='m')#Se configura el modo de paso de las neuronas IF a multipaso\n",
    "with torch.no_grad():\n",
    "    y_seq_layer_by_layer = x_seq\n",
    "    for i in range(net.__len__()):\n",
    "        y_seq_layer_by_layer = net[i](y_seq_layer_by_layer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In most cases, we don't need an explicit implementation of ``for i in range(net.__len__())``, because :class:`torch.nn.Sequential` has already done that for us. \\\n",
    "So, we write codes in the following simple style:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_seq_layer_by_layer = net(x_seq)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only difference between step-by-step and layer-by-layer is the building order of the computation graph, and their outputs are identical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net=Sequential(\n",
      "  (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, step_mode=s)\n",
      "  (1): IFNode(\n",
      "    v_threshold=1.0, v_reset=0.0, detach_reset=False, step_mode=s, backend=torch\n",
      "    (surrogate_function): Sigmoid(alpha=4.0, spiking=True)\n",
      "  )\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=s)\n",
      "  (3): IFNode(\n",
      "    v_threshold=1.0, v_reset=0.0, detach_reset=False, step_mode=s, backend=torch\n",
      "    (surrogate_function): Sigmoid(alpha=4.0, spiking=True)\n",
      "  )\n",
      "  (4): Flatten(start_dim=1, end_dim=-1, step_mode=s)\n",
      "  (5): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (6): IFNode(\n",
      "    v_threshold=1.0, v_reset=0.0, detach_reset=False, step_mode=s, backend=torch\n",
      "    (surrogate_function): Sigmoid(alpha=4.0, spiking=True)\n",
      "  )\n",
      ")\n",
      "y_seq_step_by_step=\n",
      "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 1., 1., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 1., 0., 0., 0., 1., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0., 0., 1., 0., 0., 0.]]])\n",
      "max_error=0.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from spikingjelly.activation_based import neuron, functional, layer\n",
    "T = 4\n",
    "N = 2\n",
    "C = 3\n",
    "H = 8\n",
    "W = 8\n",
    "x_seq = torch.rand([T, N, C, H, W]) * 64.\n",
    "\n",
    "net = nn.Sequential(\n",
    "layer.Conv2d(3, 8, kernel_size=3, padding=1, stride=1, bias=False),\n",
    "neuron.IFNode(),\n",
    "layer.MaxPool2d(2, 2),\n",
    "neuron.IFNode(),\n",
    "layer.Flatten(start_dim=1),\n",
    "layer.Linear(8 * H // 2 * W // 2, 10),\n",
    "neuron.IFNode(),\n",
    ")\n",
    "\n",
    "print(f'net={net}')\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    #Distribuyendo los datos multipaso con neuronas monopaso\n",
    "    y_seq_step_by_step = []\n",
    "    for t in range(T): \n",
    "        x = x_seq[t]\n",
    "        y = net(x)\n",
    "        y_seq_step_by_step.append(y.unsqueeze(0))\n",
    "\n",
    "    y_seq_step_by_step = torch.cat(y_seq_step_by_step, 0)\n",
    "\n",
    "\n",
    "    # we can also use `y_seq_step_by_step = functional.multi_step_forward(x_seq, net)` to get the same results\n",
    "\n",
    "    print(f'y_seq_step_by_step=\\n{y_seq_step_by_step}')\n",
    "\n",
    "\n",
    "    #Lo mismo pero haciendolo estableciendo directamente las neuronas en multipaso:\n",
    "    functional.reset_net(net)\n",
    "    functional.set_step_mode(net, step_mode='m')\n",
    "    y_seq_layer_by_layer = net(x_seq)\n",
    "\n",
    "    max_error = (y_seq_layer_by_layer - y_seq_step_by_step).abs().max()\n",
    "    print(f'max_error={max_error}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la versión multipaso vamos calculado capa por capa la salida de todos los X's de entrada. De esta manera vamos creciendo hacia arriba en la ejecución(a una capa superior). En la versión mono-paso, se calcula la salida para el primer paso atravesando todas las capas y a continuación se va calcula la salida para los siguientes pasos, se va creciendo hacia la derecha (hacia los siguientes pasos). Como se ve arriba, el resultado es EL MISMO.\n",
    "\n",
    "Siguiendo con el tema:\n",
    "\n",
    "There are two dimensions in the computation graph of SNN, which are the time-step and the depth dimension. As the above figures show, the propagation of SNN is the building of the computation graph.\\\n",
    "We can find that the step-by-step propagation pattern is a Depth-First-Search (DFS) for traversing the computation graph, while the layer-by-layer propagation pattern is a Breadth-First-Search (BFS) for traversing the computation graph.\n",
    "\n",
    "Although the difference is only in the building order of the computation graph, there are still some slight differences in computation speed and memory consumption of the two propagation patterns.\n",
    "\n",
    "* When using the surrogate gradient method to train SNN directly, it is recommended to use the layer-by-layer propagation pattern. When the network is built correctly, the layer-by-layer propagation pattern has the advantage of parallelism and speed. (CON SGD RECOMIENDA USAR MULTIPASO)\n",
    "* Using step-by-step propagation pattern when memory is limited. For example, a large ``T`` is required in the ANN2SNN task. In the layer-by-layer propagation pattern, the real batch size for stateless layers is ``TN`` rather than ``N`` (refer to the next tutorial). when ``T`` is too large, the memory consumption may be too large."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfm",
   "language": "python",
   "name": "tfm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
